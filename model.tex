\documentclass[12pt]{article}

\usepackage{amsmath,amsfonts}
\usepackage{graphicx}
\usepackage{showlabels}

\newcommand{\normal}[2]{{\cal N}(#1,#2)}
\newcommand{\NormalE}[3]{{\mathcal{N}}\left.\left(#1,#2\right)\right|_{#3}}
\newcommand{\xdot}{{\dot x}}
\renewcommand{\th}{^{\text{th}}}
\newcommand{\field}[1]{\mathbb{#1}}
\newcommand{\REAL}{\field{R}}
\newcommand{\RATIONAL}{\field{Q}}
\newcommand{\INTEGER}{\field{Z}}
\newcommand{\EV}[2]{\field{E}_{#1}\left[#2\right]}
\newcommand{\M}{{\cal M}}
\newcommand{\transpose}{^\top}
\newcommand{\os}[4]{{\left[ #1(#2) \right]}_{#3}^{#4}} % Object sequence
\newcommand{\ti}[2]{{#1}{(#2)}}                         % Index
\newcommand{\ts}[4]{\os{#1}{#2}{#2=#3}{#4}} % Time series
%\newcommand{\ts}[4]{{\left[ #1(#2) \right]}_{#2=#3}^{#4}} % Sequence
\newcommand{\argmin}{\operatorname*{argmin}}
\newcommand{\argmax}{\operatorname*{argmax}}
\newcommand{\cS}{{\cal S}}
\newcommand{\cA}{{\cal A}}
\newcommand{\cC}{{\cal C}}
\newcommand{\logdet}{\log\left(\left|\Sigma_D\right| \left| \Sigma_O
    \right| \right)}

\title{Model Based Motion Detection}
\author{Andy Fraser}

\begin{document}
\maketitle

\section*{Introduction}
\label{sec:introduction}

For tracking, I want the maximum a posteriori (MAP) or \emph{decoded}
track ie,
\begin{align*}
  \ts{\hat s}{\tau}{1}{T} &\equiv \argmax_{\ts{s}{\tau}{1}{T}}
  P(\ts{s}{\tau}{1}{T}|\ts{y}{\tau}{1}{T}) \\
  &= \argmax_{\ts{s}{\tau}{1}{T}} P(\ts{s}{\tau}{1}{T},\ts{y}{\tau}{1}{T}).
\end{align*}

Note that the MAP track is different than the sequence of
\emph{filtered} forecasts.  A filtered estimate, ie,
\begin{equation*}
  P(S(t)|\ts{y}{\tau}{1}{t}),
\end{equation*}
is the entire a posteriori distribution at each time given the
observations up to that time.  When I began thinking about tracking
and writing this document, I thought that the best approach would be
to do filtering.  I've left some of the work I did while thinking
about filtering in Appendix~\ref{sec:filtering} which you may safely
ignore.

\subsection*{Model Assumptions}
\label{sec:model-assumptions}

The following assumptions describe a \emph{state space model}:
\begin{description}
\item[The state dynamics are Markov:]
  \begin{equation}
    \label{eq:Markov}
    P(\ts{s}{\tau}{1}{t-1},\ts{s}{\tau}{t+1}{T}|\ti{s}{t}) =
    P(\ts{s}{\tau}{1}{t-1}|\ti{s}{t}) ~ P(\ts{s}{\tau}{t+1}{T}|\ti{s}{t}),
  \end{equation}
  ie, the future is conditionally independent of the past given the present.
\item[The observations depend only on the states:] Or more precisely,
  the observation at time $t$ is conditionally independent of
  everything else given the state at time $t$, ie,
  \begin{equation}
    \label{eq:IndependentY}
    P(\ti{y}{t},z|\ti{s}{t}) =  P(\ti{y}{t}|\ti{s}{t}) ~  P(z|\ti{s}{t})
  \end{equation}
  where $z$ can be any collection of other states and observations.
\end{description}
If these assumptions hold, the following functions completely describe
a model:
\begin{description}
\item[State transition probability:] $P(\ti{s}{t+1}|\ti{s}{t})$
\item[Conditional observation probability:] $P(\ti{y}{t}|\ti{s}{t})$
\item[Initial state distribution] $P(\ti{s}{1})$
\end{description}

\subsection*{Decoding}
\label{sec:decoding}

I will use the following definitions to describe decoding:
\begin{align*}
  u(\ts{s}{\tau}{1}{t}) & \quad \text{Utility of state sequence }
  \ts{s}{\tau}{1}{t}\\
  & \quad \equiv \log \left( P(\ts{y}{\tau}{1}{t},\ts{s}{\tau}{1}{t} \right)
  \\
  \nu(s,t) & \quad \text{Utility of best sequence ending with }
  \ti{s}{t} = s \\ 
  &  \quad \equiv \max_{\ts{s}{\tau}{1}{t}:\ti{s}{t}=s} u(\ts{s}{\tau}{1}{t}) \\
  u'(s,s',t) & \quad \text{Utility of best sequence ending with }
  \ti{s}{t},\ti{s}{t+1} = s,s' \\
  &  \quad \equiv \max_{\ts{s}{\tau}{1}{t+1}:\ti{s}{t}=s \&\ti{s}{t+1}=s'}
  u(\ts{s}{\tau}{1}{t+1}) \\
  B(s,t) & \quad \text{Best predecessor state given } \ti{s}{t+1}=s   
\end{align*}
I can evaluate the functions $B(*,t)$ and $\nu(*,t)$ recursively as
follows:
\begin{align*}
  u'(s,s',t) &= \nu(s,t) + \log\left( P_{\ti{s}{t+1}|}(s'|s) \right) +
  \log\left( P_{\ti{y}{t+1}|\ti{s}{t+1}}(\ti{y}{t+1}|s') \right) \\
  B(s,t) &= \argmax_{s'} u'(s',s,t)) \\
  \nu(s,t+1) &= u'(B(s,t),s,t)
\end{align*}
Given the functions $B(*,t)$ and $\nu(*,t)$ $\forall
t\in[1,\ldots,T]$, the following procedure decodes the best sequence
of states $ \ts{\hat s}{\tau}{1}{T}$ from a sequence of observations $
\ts{y}{\tau}{1}{T}$
\begin{align*}
  {\ti{{\hat s}}{T}} &= \argmax_s \nu(s,T) \\
  & \text{for } t \text{ from } T-1 \text{ to } 1: \\
  & \quad \ti{\hat s}{t} = B( \ti{\hat s}{t+1},t)
\end{align*}

\section{Model Version One}
\label{sec:model1}

In this section I describe the basic model \emph{MVI}.  I'll develop
algorithms and write code for \emph{MVI} for the baseline prototype of
the watcher project.  Later, I will compare proposed enhancements
against the performance of \emph{MVI}.

The number of moving objects is a constant $N$ over time.  At each
time $t$, the separate objects $\ti{s}{t,j}$ that constitute the state
evolve independently of each other.  The following equations describe
$P(\ti{s}{t+1,j}|\ti{s}{t,j})$, ie, the dynamics of each object:
\begin{subequations}
  \label{eq:dynamics}
  \begin{align}
    \ti{s}{t+1,j} &= A  \ti{s}{t,j} + \ti{\epsilon}{t,j}, &
    \ti{\epsilon}{t,j} &\sim \normal{0}{\Sigma_{D}} \text{ iid} \\
    A &= \begin{bmatrix}
      1 & 0 & \tau & 0 \\
      0 & 1 & 0 & \tau \\
      0 & 0 & 1 & 0 \\
      0 & 0 & 0 & 1
    \end{bmatrix} &
    \Sigma_{D} &= \begin{bmatrix}
      \sigma^2_{xD} & 0 & 0 & 0 \\
      0 & \sigma^2_{xD} & 0 & 0 \\
      0 & 0 & \sigma^2_{\xdot D} & 0 \\
      0 & 0 & 0 & \sigma^2_{\xdot D}
    \end{bmatrix}
  \end{align}
\end{subequations}
Each object has the following components at time $t$:
\begin{align*}
  &&s_{0}(t,j) & \text{ horizontal position} \\
  &&s_{1}(t,j) & \text{ vertical position} \\
  &&s_{2}(t,j) & \text{ horizontal velocity} \\
  &&s_{3}(t,j) & \text{ vertical velocity}
\end{align*}
In addition to the moving objects, a complete description of a state
$\ti{s}{t}$ includes a map $\ti{M}{t}\in \M$, where $\M$ is the set of
permutations of $N$ items.  I assume that $\ti{M}{t}$ is distributed
uniformly and independently of everything else, ie,
\begin{equation*}
  P(\ti{M}{t}) = \frac{1}{\left| \M\right|} =  \frac{1}{N!}.
\end{equation*}

An observation vector consists of locations
$\ti{y}{t}=\os{y}{t,i}{i=1}{N}$.  The probability that state
$\ti{s}{t}$ would produce observation $\ti{y}{t}$ is\footnote{This
  observation model describes indistinguishable observations.  An
  easier alternative would be objects that had different colors, or
  even easier, objects that had observable unique tags.}
\begin{equation}
  \label{eq:ob}
  P(\ti{y}{t}|\ti{s}{t}) =
    \frac{1}{\left|\M \right|} \sum_{M \in \M}
    \prod_{i=1}^{N} P(\ti{y}{t,M(i)}|\ti{s}{t,i}).
\end{equation}
with normal conditional observation distributions
\begin{equation*}
  \ti{y}{t,i}|\ti{s}{t,j} \sim
  \begin{cases}
    \NormalE{O\ti{s}{t,j}}{\Sigma_o}{\ti{y}{t,i}} & i = M(j) \\
    \text{Uniform} & \text{Otherwise}
  \end{cases}
\end{equation*}
where each mean comes from the projection
\begin{equation*}
  O = \begin{bmatrix} 1 & 0 & 0 & 0\\
    0 & 1 & 0 & 0 \end{bmatrix}
\end{equation*}
and each covariance is
\begin{equation*}
  \Sigma_o = \begin{bmatrix} \sigma_{xo}^2 & 0 \\ 0 &
    \sigma_{xo}^2 \end{bmatrix}.
\end{equation*}
In summary, aside from the initial state distribution, the model has
the following 3 degrees of freedom:
\begin{center}
  \begin{tabular}{|cp{15em}c|}
    \hline
    Symbol & Description & Degrees of freedom \\
    \hline
    $\Sigma_D$ & Dynamical noise & 2 \\
    $\Sigma_o$ & Observation noise & 1 \\
    \hline
  \end{tabular} 
\end{center}

\subsection{Decoding}
\label{sec:decode1}

A solution to the decoding problem
\begin{align*}
  \ts{\hat s}{\tau}{1}{T} &\equiv \argmax_{\ts{s}{\tau}{1}{T}}
  P(\ts{s}{\tau}{1}{T}|\ts{y}{\tau}{1}{T}) \\
            &=  \argmax_{\ts{s}{\tau}{1}{T}} P(\ts{s}{\tau}{1}{T},\ts{y}{\tau}{1}{T})
\end{align*}
contains only a single sequence of permutations $\ts{\hat
  M}{t}{1}{T}$.  Thus I need not approximate a mixture of Gaussians.

\subsubsection{Single Sequence}
\label{sec:single-sequence}

I'll begin by considering decoding a trajectory of a single object
from a single sequence of observations.  Using the notation in the
introduction, and assuming that $\nu(s,t)$ is quadratic, I can write
the following recursion:
\begin{align}
  \nu(s,t) &= -\frac{1}{2}(s-\mu_{t})^T
    \Sigma_{t}^{-1}(s-\mu_{t}) + R_t \nonumber \\
  \label{eq:decode_u'}
  u'(s,s',t) &= \nu(s,t) -\frac{1}{2} \logdet  - 
  \frac{1}{2}(s'-As)^T \Sigma_{D}^{-1} (s'-As)  \nonumber \\
  &\quad - \frac{1}{2}(\ti{y}{t+1} - O s')^T \Sigma_{O}^{-1}(\ti{y}{t+1}
    - O s') \\
  B(s,t) &= \argmax_{q} u'(q,s,t) \nonumber \\
  \label{eq:decode_B}
  &= \left( \Sigma_t^{-1} + A^T \Sigma_D^{-1} A \right)^{-1} \left(
    \Sigma_t^{-1} \mu_t + A^T \Sigma_D^{-1} s \right) \\
  \nu(s,t+1) &= u'(B(s,t),s,t) \nonumber \\
  &\equiv  -\frac{1}{2}(s-\mu_{t+1})^T
  \Sigma_{t+1}^{-1}(s-\mu_{t+1}) + R_{t+1} \nonumber \\
  \label{eq:new_Sigma}
  \Sigma_{t+1}^{-1} & = O^T\Sigma_O^{-1} O + \left( \Sigma_D + A \Sigma_t
    A^T \right)^{-1} \\
  \label{eq:new_mu}
  \mu_{t+1} &= A \mu_t + \Sigma_{t+1} O^T \Sigma_O^{-1} \Delta_y \\
  \label{eq:new_R}
  R_{t+1} &= R_t -\frac{1}{2} \left( \Delta_y^T \Sigma_y^{-1} \Delta_y
    + \logdet \right),
\end{align}
where
\begin{align}
  \label{def:Delta_y}
  \Delta_y &\equiv \ti{y}{t+1} - OA \mu_t \\
  \label{def:Sigma_y}
  \Sigma_y &\equiv O(A\Sigma_t A^T + \Sigma_D)O^T + \Sigma_O \\
  \label{eq:Sigma_yI}
  \Sigma_y^{-1} &= \Sigma_O^{-1} - \Sigma_O^{-1} O \Sigma_{t+1} O^T
  \Sigma_O^{-1}.
\end{align}
While Defs.~\eqref{def:Delta_y} and  \eqref{def:Sigma_y} are simply
abbreviations, Eqn.~\eqref{eq:Sigma_yI} requires effort to derive.

I derive \eqref{eq:decode_B} by
solving\footnote{The derivation of \eqref{eq:decode_B}:
  \begin{align*}
    \frac{d u'(q,s,t)}{d q} &= -\Sigma_t^{-1}(q-\mu_t) + A^T \Sigma_D^{-1}
    (s - Aq) \\
    &= \Sigma_t^{-1}\mu_t + A^T \Sigma_D^{-1} s -(\Sigma_t^{-1} +
    A^T\Sigma_D^{-1}A)q \\
    q &= \left( \Sigma_t^{-1} + A^T\Sigma_D^{-1}A\right)^{-1} \left(
      \Sigma_t^{-1}\mu_t + A^T \Sigma_D^{-1} s \right)
  \end{align*}
}
\begin{equation*}
  \frac{d u'(q,s,t)}{d q} = 0.
\end{equation*}
Note that the independent variable $s$ in \eqref{eq:decode_B} is the
state at the future time $t+1$, while in \eqref{eq:decode_u'}, $s$ is
the state at the earlier time $t$.  See Appendix~\ref{app:decode} for
the derivation of \eqref{eq:new_Sigma}, \eqref{eq:new_mu}, and
\eqref{eq:new_R}.  I am surprised that the resulting recursion for
$\nu(s,t)$ is exactly Kalman filtering.

For efficiency, use the following procedure to implement the forward
recursion:
\begin{description}
\item[Calculate the state forecast mean and covariance:]
  \begin{align*}
    \mu_a &= A\mu_t \\
    \Sigma_a &= A \Sigma_t A^T + \Sigma_D
  \end{align*}
\item[Calculate the inverse covariance of the forecast observation:]
  \begin{equation*}
   \Sigma_y^{-1} = \left( O\Sigma_a O^T + \Sigma_O \right)^{-1}
  \end{equation*}
\item[Calculate the Kalman gain matrix:]
  \begin{equation*}
    K = \Sigma_a O^T \Sigma_y^{-1}
  \end{equation*}
\item[Calculate the forecast error:]
  \begin{equation*}
    \Delta_y = \ti{y}{t+1} - O\mu_a
  \end{equation*}
\item[Calculate the updated mean and covariance:]
  \begin{align}
    \label{eq:Sigma_alg}
    \mu_{t+1} &= \mu_a +  K\Delta_y \\
    \label{eq:mu_alg}
    \Sigma_{t+1} &= (1-KO)\Sigma_a
  \end{align}
\item[Calculate the new $R$:]
  \begin{equation}
    \label{eq:R_alg}
    R_{t+1} = R_t - \frac{1}{2} \left(\Delta_y^T \Sigma_y^{-1}
      \Delta_y \right)
  \end{equation}
\end{description}

\subsubsection{Multiple Objects}
\label{sec:multiple}

Consider the possible permutations at each time to be a discrete
component of the state.  Thus
\begin{equation*}
  \ti{s}{t} \in {\cal S} \equiv {\cal M} \times {\cal X}^{N},
\end{equation*}
where $N$ is the number of objects or targets, $\cal M$ is the set of
permutations of $N$ objects, and ${\cal X}$ is the state space of a
single object.  Denoting the components of a particular state as
follows: \newcommand{\bx}{{\mathbf{x}}}
\begin{align*}
  s &\equiv (M,\bx) \\
  M & \text{ is a permutation} \\
  \bx &\equiv (x_1,x_2,\ldots,x_N),
\end{align*}
I write
\begin{align*}
  u'(M,\bx,M',\bx',t) &= \nu(M,\bx) + \log \left(
    P(M',\bx'|M,\bx)\right) + \log \left(
    P(\ti{y}{t+1}|M',\bx')\right) \\
  P(M',\bx'|M,\bx) &= P(\bx'|M',M,\bx) P(M'|M,\bx) \\
  &= \frac{1}{N!} P(\bx'|\bx) \\
  u'(M,\bx,M',\bx',t) &= \nu(M,\bx) - \log(N!) + \log \left(
    P(\bx'|\bx)\right) + \log \left( P(\ti{y}{t+1}|M',\bx')\right) \\
  \nu(M,\bx,t) &= \sum_k \nu(M,x_k,t) \\
  &= \sum_k \nu(M,\bar x_k) + \sum_k \left (\nu(M,x_k,t) - \nu(M,\bar
    x_k) \right) \\
  &= \sum_k R(k,t|M) + \sum_k \left (\nu(x_k,t|M) -  R(k,t|M) \right),
\end{align*}
where $\bar x_k$ is the $x$ value that maximizes $\nu(M,x_k,t)$ for a
the best permutation sequence ending in the given $M$ and $R(k,t|M)$ is
the remainder from Eqn.~\eqref{eq:R_alg} for the $k^{\text{th}}$
object given the that sequence of permutations.  Each $B(s,t)$ maps
from $(M',s')$ at time $t+1$ to the best pair $(M,s)$ at time $t$, and
each $\nu(s,t)$ maps from a pair $(M,s)$ at time $t$ to the utility of
the best path ending at $(M,s,t)$.  While I use the values of $\sum_k
R(k,t|M)$ to determine the best predecessor permutation.  In the
calculation of $R(k,t|M)$ I drop the term $\logdet$ from
Eqn.~\eqref{eq:new_R} and $\log(N!)$ because they are independent of
both $M$ and $s$.

I have implemented an algorithm around the following recursion step:
\begin{verse}
  At time $t$ given $(\mu(M,k,t), \Sigma(M,k,t), R(M,k,t))~\forall
  (M,k)$:\\
  For each possible permutation $M$ at time $t+1$:\\
  \hspace{2em} For each possible predecessor $M'$ at time $t$:\\
  \hspace{4em}  Calculate $u'(M',M,t) = \sum_k R(k,t+1|M',M)$ \\
  \hspace{2em} Set $B_M(M,t+1) = \tilde M = \argmax_{M'}u'(M',M,t)$\\
  \hspace{2em} For each object $k$:\\
  \hspace{4em} Calculate $(\mu(M,k,t+1), \Sigma(M,k,t+1), R(M,k,t+1))$\\
  \hspace{4em} from Eqns.~\eqref{eq:Sigma_alg}--\eqref{eq:R_alg} using
  the initial values\\
  \hspace{4em} $(\mu(\tilde M,k,t), \Sigma(\tilde M,k,t),R(\tilde
  M,k,t))$
\end{verse}

\section{Model Version Two: Variable Visibility}
\label{sec:model2}

In MVI of the previous section, I described the state at each time as
a combination of the position and velocities of the targets and the
map from targets to observations.  Recall from
Section~\ref{sec:multiple}:
\begin{align*}
  s &\equiv (M,\bx) \\
  M & \text{ is a permutation} \\
  \bx &\equiv (x_1,x_2,\ldots,x_N).
\end{align*}
For \emph{MVII} I introduce a discrete \emph{visibility} for each
target, ie, \newcommand{\bv}{{\mathbf{v}}}
\begin{align*}
  s &\equiv (M,\bx,\bv) \\
  \bv &\equiv (v_1,v_2,\ldots,v_N).
\end{align*}
I assume that only targets with $v_k=0$ are visible and that
visibility ($v$), phase space dynamics ($x$), and association ($M$) are
independent.

The following pair of equations define the model:
\begin{equation}
  P(\ti{s}{t+1}|\ti{s}{t}) = \frac{1}{\left| \M \right|} \prod_i
  P(\ti{x_i}{t+1}|\ti{x_i}{t})\, P(\ti{v_i}{t+1}|\ti{v_i}{t})
\end{equation}
\begin{equation}
  P(y|s) =
  \begin{cases}
    0 & \text{If } \left| \{i:v_i=0 \} \right| \neq \text{number of
      observations} \\
    \prod_{i:v_i=0} P(y(M(i))|x_i) & \text{Otherwise}
  \end{cases}
\end{equation}
The only new parameters are $P(\ti{v_i}{t+1}|\ti{v_i}{t})$ the
probabilities of transitions between visibility states.  I find the
modifications to algorithms for MVI required for MVII by observing
\begin{align}
  u'(M,\bx,\bv,M',\bx',\bv't) &= \nu(M,\bx,\bv) - \log(N!) + \log \left(
    P(\bx'|\bx)\right) \nonumber \\
  & \quad + \log \left( P(\bv'|\bv)\right) + \log \left(
  P(\ti{y}{t+1}|M',\bx')\right)
\end{align}
and noting that $\log \left( P(\bv'|\bv)\right)$ is the only new term
and
\begin{equation}
  \label{eq:1}
   \log \left( P(\bv'|\bv)\right) = \sum_i \log \left(
     P(v_i'|v_i)\right),
\end{equation}
where the subscript $i$ identifies the target.

Doing a forward iteration on a target that is not visible requires
expressions like Eqns.~\eqref{eq:decode_u'}-\eqref{eq:Sigma_yI} but
without an observation, ie,


\begin{align}
  \nu(s,t) &= -\frac{1}{2}(s-\mu_{t})^T
    \Sigma_{t}^{-1}(s-\mu_{t}) + R_t \nonumber \\
  u'(s,s',t) &= \nu(s,t) -\frac{1}{2} \log(\left|\Sigma_D\right|)  - 
  \frac{1}{2}(s'-As)^T \Sigma_{D}^{-1} (s'-As)  \nonumber \\
  B(s,t) &= \argmax_{q} u'(q,s,t) \nonumber \\
  &= \left( \Sigma_t^{-1} + A^T \Sigma_D^{-1} A \right)^{-1} \left(
    \Sigma_t^{-1} \mu_t + A^T \Sigma_D^{-1} s \right) \nonumber \\
  \nu(s,t+1) &= u'(B(s,t),s,t) \nonumber \\
  &\equiv  -\frac{1}{2}(s-\mu_{t+1})^T
  \Sigma_{t+1}^{-1}(s-\mu_{t+1}) + R_{t+1} \nonumber \\
  \label{eq:new_Sigma_noy}
  \Sigma_{t+1} & = \left( \Sigma_D + A \Sigma_tA^T \right) \\
  \label{eq:new_mu_noy}
  \mu_{t+1} &= A \mu_t \\
  \label{eq:new_R_noy}
  R_{t+1} &= R_t -\frac{1}{2}  \log(\left|\Sigma_D\right|).
\end{align}

\section{Model Version Three: Background False Alarms}
\label{sec:model3}

This model, \emph{MVIII}, generates hits like MVII except that in
addition it generates noise hits or \emph{false alarms}.  The false
alarms are drawn from the initial $y$ distribution
$\normal{\mu_0}{\Sigma_0}$ and the number of hits is drawn from a
Poisson distribution with expected value $\lambda$.  The number of
false alarms, $N_{\text{FA}}$, is a characteristic of a state, ie, $s
\equiv (M,\bx,\bv,N_{\text{FA}})$ and
\begin{equation}
  \label{eq:2}
  P(\ti{s}{t+1}|\ti{s}{t},\ti{M}{t+1},\ti{\bx}{t+1}) =
  \frac{e^{-\lambda}\lambda^{N_{\text{FA}}}}{N_{\text{FA}}!}.
\end{equation}
And the probability density of $y$ given that it is a false alarm is
\begin{equation*}
  P(y|\text{FA}) = \NormalE{\mu_0}{\Sigma_0}{y}.
\end{equation*}
For decoding, if you attribute the observations $y_1^{N_{\text{FA}}}$
to false alarms at time $t$, add\footnote{See Appendix
  \ref{sec:counting}} $\sum_k^{N_{\text{FA}}} \log(P(y_k|\text{FA}))$
and $\log \left( e^{-\lambda} \lambda^{N_{\text{FA}}} \right)$ to the
value of $\nu$.\marginpar{Are you sure?}


\section{Model Version Four: Variable Number of Targets}
\label{sec:model4}

\emph{MVIV} creates $N_{\text{new}}$ new targets at each time step.
$N_{\text{new}}$ has a Poisson distribution with a small mean; at most
times there are no new states.  The positions and velocities of the
new states have the same distribution as initial states.  I assume
that new states are visible when they arise to avoid carrying many
invisible states for decoding.

In the decoding algorithm, the cost of attributing the observations
$y_1^{N_{\text{new}}}$ to new targets at time $t$ is the
addition\footnote{See Appendix \ref{sec:counting}} of
$\sum_k^{N_{\text{new}}} \log(P(y_k|\text{new}))$ and $\log \left(
  e^{-\lambda} \lambda^{N_{\text{new}}}\right)$ to the value of
$\nu$.\marginpar{Are you sure?}

While it would be simpler to treat false alarms and new targets with
the same model mechanism, since new targets will frequently arise at
edges while false alarms will happen in other areas more frequently, I
expect better performance by using separate mechanisms to model the
two kinds of events.

\textbf{Caution:} Since the dimension of the state changes with time,
we should make sure that the results of algorithms do not depend on
coordinates.

Ultimately MVIV will have the following properties:
\begin{itemize}
\item Start with a random number of targets
\item New targets created randomly
\item Old targets removed after being invisible for some number of
  frames
\end{itemize}

\section{Algorithms and Approximations}
\label{sec:algorithms}

For MVIV, a state $s \equiv (M, \bx, \bv, N_{\text{FA}},
N_{\text{targets}})$ has the following components:
\begin{description}
\item[$M$:] A map from a subset of the targets to a subset of the observations
\item[$\bx$:] The positions of the targets
\item[$\bv$:] The \emph{visibility} of each of the targets
\item[$N_{\text{FA}}$:] The number of false alarms (derivable from $M$)
\item[$N_{\text{targets}}$:] The number of targets (derivable from $\bx$)
\end{description}
I divide the components in two parts: The \emph{target} part
$(\bx,\bv)$; and the \emph{association} part, $\cA \equiv (M,
N_{\text{FA}}, N_{\text{targets}})$.  For each time $t$ in the forward
pass of the Viterbi algorithm, I need $\nu(s,t)$ and $B(s,t)$.  I keep
track of the association parts of states, treating them as discrete
states in the Viterbi algorithm.  At time $t$ each $\cA$ has: An
explanation for each observation; a pointer to the best predecessor,
$B(\cA,t)$, which inductively also explains all previous observations;
and a utility $\nu(\cA,t) = \max_{\bx,\bv} \nu(s,t)$.  To make the $B$
and $\nu$ functions complete, I keep track of a mean $\mu_k(t)$ and a
covariance $\Sigma_k(t)$ for each target $(\bx_k,\bv_k)$ used as part
of an explanation in each $\cA$ or any of the predecessors (See
Eqns.~\eqref{eq:mu_alg} and \eqref{eq:Sigma_alg}).

\subsection{Clusters}
\label{sec:clusters}

I believe that if, over an interval of time, the observations are
clustered into groups that are far apart, I can reduce the number of
computations in the forward part of the Viterbi algorithm by breaking
the problem into pieces that match the clusters in the data.

I define a cluster of associations as a set associations each of which
along with its predecessors explains the same set of observations.

\subsubsection{Merging}
\label{sec:merging}

To merge two clusters, $\cC_1$ and $\cC_2$, create a new association
from each pair drawn from the two clusters, ie,
\begin{align}
  \text{Merge}(\cC_1,\cC_2) &= \cC_3 \\
  \forall \cA_{i}, \cA_{j} \text{ such that } \cA_{i} \in \cC_1 &\text{
    and } \cA_{j} \in \cC_2 ~~ \cA_k = \text{Merge}(\cA_{i}, \cA_{j})
  \in \cC_3 \\
  \text{Merge}(\cA_{i}, \cA_{j}): \\
  M_k &= \text{concatenate } M_i, M_j \\
  N_{\text{FA},k} &= N_{\text{FA},i} + N_{\text{FA},k} \\
  N_{\text{targets},k} &= N_{\text{targets},i} + N_{\text{targets},k}
  \\
  \nu_k &= \nu_i +\nu_j
\end{align}

\subsubsection{Branching}
\label{sec:branching}

Branching, $(\cC_1,\cC_2) = \text{Branch}(\cC_3)$ seems harder.  In
particular,
\begin{description}
\item[Q:] How should $\nu$ be apportioned between the children?
\item[A:] So that the \emph{Merge} of any pair of children yields a
  parent.
\item[Q:] Is that necessary and sufficient?
\item[A:] I think so.  I want to allow final selection of any child
  association from $\cC_1$ along with final selection of any child
  association from $\cC_2$, and this does the trick.
\end{description}
First branch the association with the highest score, then discard all
associations whose branchings are inconsistent with the first.  A
branching is inconsistent if the targets going into the branches do
not explain the same subsets of observations from the first time to
the present.  By branching one may discard an assocaition that would
prove to be superior on the basis of future observations.

\subsubsection{Forward Step}
\label{sec:forward_b_m}

Having processed observations $\ts{y}{\tau}{1}{t-1}$ implement the
following steps to process the observations $\ti{y}{t}$
\begin{enumerate}
\item Find clusters of targets $\ti{x}{t-1}$ defined by their children
  $\ti{x}{t}$ explaining clusters of observations $\ti{y}{t}$
  \begin{description}
  \item[Q:] What about invisible targets?
  \item[A:] Cluster membership for invisible targets is determined by
    children.  If a target has no visible children, then it is in a
    cluster by itself.
  \end{description}
\item Reform clusters of associations based on step 1
\item Propagate the clusters
\end{enumerate}

\appendix
\section{Counting}
\label{sec:counting}

I am confused by counting problems in the models.
\begin{description}
\item[Q:] Why in Section \ref{sec:model4} do I add the term $\log
  \left( e^{-\lambda} \lambda^{N_{\text{new}}} \right)$ instead of
  $\log \left(
    \frac{e^{-\lambda}\lambda^{N_{\text{new}}}}{N_{\text{new}}!}\right)$?
  (There is a similar term in Section \ref{sec:model3} for
  $N_{\text{FA}}$.)
\item[A:] There are $N_{\text{new}}!$ different, but operationally
  equivelent, ways to assign $N_{\text{new}}$ targets to
  $N_{\text{new}}$ locations.
\item[Q:] Suppose that at time $t=0$ targets sit at locations
  $\ti{x_a}{0}$ and $\ti{x_b}{0}$ and that at time $t=1$ targets sit
  at locations $\ti{x_c}{0}$ and $\ti{x_d}{0}$.  If I say that
  $\ti{s}{0}\equiv \left(x_a,x_b \right)$ and $\ti{s}{1}\equiv
  \left(x_c,x_d \right)$, should I write
  \begin{equation}
    \label{eq:3}
    P(\ti{s}{1}|\ti{s}{0}) =  P(x_c|x_a) \,  P(x_d|x_b) +  P(x_c|x_b)
    \,  P(x_d|x_a)
  \end{equation}
  or simply
  \begin{equation}
    \label{eq:4}
    P(\ti{s}{1}|\ti{s}{0}) =  P(x_c|x_a) \,  P(x_d|x_b)
  \end{equation}
\item[A:] Use \eqref{eq:4}.  The second term in \eqref{eq:3} is part
  of a different sequence of state transisitons.
\end{description}

\section{Derivation of Formulas for Decoding the Trajectory of a Single Object}
\label{app:decode}

I obtain \eqref{eq:new_Sigma} and \eqref{eq:new_mu} by expanding
$u'(B(s,t),s,t)$ and completing the square.  I'll abbreviate $B(s,t)$
with $B$, using the notation
\begin{align*}
  B &\equiv \left( \Sigma_t^{-1} + A^T \Sigma_D^{-1} A \right)^{-1}
  \left( \Sigma_t^{-1} \mu_t + A^T \Sigma_D^{-1} s \right) \\
  &= G + Fs \\
  G &\equiv \left( \Sigma_t^{-1} + A^T \Sigma_D^{-1} A \right)^{-1}
  \Sigma_t^{-1} \mu_t \\
  F &\equiv  \left( \Sigma_t^{-1} + A^T \Sigma_D^{-1} A \right)^{-1}
  A^T \Sigma_D^{-1}.
\end{align*}
I find
\begin{align*}
  \nu(s,t+1) &= -\frac{1}{2}(B-\mu_{t})^T \Sigma_{t}^{-1}
  (B-\mu_{t}) + R_t\\
  &\quad - \frac{1}{2} (s-AB)^T \Sigma_{D}^{-1} (s-AB)\\
  &\quad - \frac{1}{2}(\ti{y}{t+1}-O s)^T \Sigma_{O}^{-1}
  (\ti{y}{t+1}-Os) -\frac{1}{2} \logdet\\
  -2 \nu(s,t+1) &= (G-\mu_{t}+Fs)^T \Sigma_{t}^{-1} (G-\mu_{t}+Fs) \\
  &\quad + ((1-AF)s-AG)^T \Sigma_{D}^{-1} ((1-AF)s-AG)\\
  &\quad + (\ti{y}{t+1}-O s)^T \Sigma_{O}^{-1} (\ti{y}{t+1}-Os) -2R_t \\
  &\equiv s^T q s - 2s^T l + c.
\end{align*}
To express $\nu_{t+1}$ in terms of $\Sigma_{t+1}$, $\mu_{t+1}$, and
$R_{t+1}$, I will use the following formulas:
\begin{align*}
  \Sigma_{t+1}^{-1} &= q \\
  \mu_{t+1} &= \Sigma_{t+1} l \\
  R_{t+1} &= -\frac{1}{2} \left( c - \mu_{t+1}^T \Sigma_{t+1}^{-1}
    \mu_{t+1} \right) .
\end{align*}
The quadratic term is
\begin{align*}
  q &= F^T\Sigma_t^{-1}F + (1-AF)^T\Sigma_D^{1-}(1-AF) +
  O^T\Sigma_O^{-1}O \\
  &= O^T\Sigma_O^{-1}O + \Sigma_D^{-1} - \Sigma_D^{-1}A
  ( \Sigma_t^{-1} + A^T\Sigma_D^{-1}A )^{-1}A^T\Sigma_D^{-1}\\
  &= O^T\Sigma_O^{-1}O + (\Sigma_D + A \Sigma_t A^T)^{-1}
\end{align*}
where the last line follows from the matrix inversion lemma, ie,
\begin{equation*}
  (L^{-1} + H^T J^{-1} H)^{-1} = L - LH^T (HLH^T + J)^{-1} HL.
\end{equation*}
Equation~\eqref{eq:new_Sigma} follows from $\Sigma_{t+1}^{-1} = q$.
The linear term is
\begin{align*}
  l &= O^T\Sigma_O^{-1}y(t+1) - F^T \Sigma_t^{-1}(G-\mu_t) +
  (1-AF)^T\Sigma_D^{-1}AG \\
  &= O^T\Sigma_O^{-1}y(t+1) + \Sigma_D^{-1}A \left( \Sigma_t^{-1} +
    A^T \Sigma_D^{-1} A \right)^{-1} \Sigma_t^{-1} \mu_t.
\end{align*}

While I could (and have with much pain) derive Eqn.~\eqref{eq:new_mu}
from the formula $\mu_{t+1} = \Sigma_{t+1} l$, here I only verify that
$q \mu_{t+1} = l$.  I will use the following lemma:
\begin{align*}
  (q-O^T\Sigma^{-1}O)A &= \left( \Sigma_D^{-1} - \Sigma_D^{-1} A (
    \Sigma_t^{-1} + A^T \Sigma_D^{-1} A)^{-1} A^T \Sigma_D^{-1}
  \right) A \\
  &= (\Sigma_D + A \Sigma_t A^T)^{-1} A \quad \text{ by matrix inversion
    lemma} \\
  &= (A^{-1} \Sigma_D + \Sigma_t A^T)^{-1} \\
  &= (\Sigma_t^{-1} A^{-1} \Sigma_D + A^T)^{-1} \Sigma_t^{-1}\\
  &= \Sigma_D^{-1} (\Sigma_t^{-1} A^{-1}  + A^T\Sigma_D^{-1})^{-1} \Sigma_t^{-1}\\
  &= \Sigma_D^{-1} A (\Sigma_t^{-1}  + A^T\Sigma_D^{-1} A)^{-1} \Sigma_t^{-1}.
\end{align*}
Now the verification is simply:
\begin{align*}
  q \mu_{t+1} &= qA\mu_t + O^T \Sigma_O^{-1} \ti{y}{t+1} - O^T
  \Sigma_O O A \mu_t \\
  &= O^T \Sigma_O^{-1} \ti{y}{t+1} + (q - O^T \Sigma_O O) A \mu_t \\
  &= O^T\Sigma_O^{-1}y(t+1) + \Sigma_D^{-1}A \left( \Sigma_t^{-1} +
    A^T \Sigma_D^{-1} A \right)^{-1} \Sigma_t^{-1} \mu_t \quad \text{
    by the lemma}\\
  &= l.
\end{align*}

Using the the following abbreviation and calculation
\begin{align*}
  H &\equiv (\Sigma_t^{-1} + A^T \Sigma_D^{-1}A)^{-1} \Sigma_t^{-1} \\
  &= 1 - \Sigma_t A^T(A\Sigma_t A^T + \Sigma_D)^{-1} A \quad \text{ By
    matrix inversion lemma}
\end{align*}
I write the constant term as
\begin{align*}
  c &= \mu_t^T \left( (H-1)^T\Sigma_t^{-1} (H-1) + H^TA^T\Sigma_D^{-1}
    AH \right) \mu_t + \ti{y^T}{t+1} \Sigma_O^{-1}
  \ti{y}{t+1} - 2R_t + \logdet\\
  &= \mu_t^T  A^T(A\Sigma_t A^T + \Sigma_D)^{-1}A \mu_t
  + \ti{y^T}{t+1} \Sigma_O^{-1} \ti{y}{t+1} - 2R_t  + \logdet,
\end{align*}
and find
\begin{align*}
  R_{t+1} = R_t -\frac{1}{2} \Big( &
  \mu_t^T  A^T(A\Sigma_t A^T + \Sigma_D)^{-1}A \mu_t 
   - \mu_{t+1}^T \Sigma_{t+1}^{-1} \mu_{t+1} \\
  & + \ti{y^T}{t+1} \Sigma_O^{-1} \ti{y}{t+1} + \logdet \Big).
\end{align*}
To verify Eqn.~\eqref{eq:new_R} I'll use the following notation and
equalities:
\begin{align}
  X &\equiv \Sigma_D + A \Sigma_t A^T \\
  l &= O^T\Sigma_O^{-1} \ti{y}{t+1} + X^{-1} A \mu_t \\
  \mu_{t+1} &= \Sigma_{t+1} l \\
  \mu_{t+1}^T \Sigma_{t+1} \mu_{t+1} &= l^T \Sigma_{t+1} l \\
  \Sigma_{t+1} &= (O^T\Sigma_O^{-1}O + X^{-1})^{-1} \\
  &= X - XO^T(OXO^T + \Sigma_O)^{-1} OX \\
  \Sigma_y &= O(A\Sigma_t A^T + \Sigma_D) O^T + \Sigma_O \\
  &= OXO^T + \Sigma_O \\
  \Sigma_y^{-1} &= \Sigma_O^{-1} - \Sigma_O^{-1} O (O^T\Sigma_O^{-1}O
  + X^{-1})^{-1}O^T \Sigma_O^{-1} \\
  &= \Sigma_O^{-1} - \Sigma_O^{-1} O \Sigma_{t+1}O^T \Sigma_O^{-1} \\
  \Delta_R &\equiv \mu_t^TA^T X^{-1} A \mu_t - \mu_{t+1}^T
  \Sigma_{t+1} \mu_{t+1} + \ti{y}{t+1}^T \Sigma_O^{-1} \ti{y}{t+1}.
\end{align}
Using the derivation
\begin{align*}
  \Sigma_O^{-1} O \Sigma_{t+1} X^{-1} &=
  \Sigma_O^{-1}O(1-XO^T\Sigma_yO) \\
  &= \Sigma_O^{-1}(1-OXO^T\Sigma_y^{-1})O \\
  &= \Sigma_O^{-1}(\Sigma_y-OXO^T)\Sigma_y^{-1}O \\
  &= \Sigma_O^{-1}(\Sigma_O)\Sigma_y^{-1}O \\
  &= \Sigma_y^{-1}O \\
\end{align*}
and considering the three terms of
\begin{align*}
  l^T \Sigma_{t+1} l = & (O^T\Sigma_O^{-1} \ti{y}{t+1})T \Sigma_{t+1}
  (O^T\Sigma_O^{-1} \ti{y}{t+1}) \\
  + & 2(O^T\Sigma_O^{-1} \Sigma_{t+1} X^{-1}A\mu_t \\
  + & (X^{-1}A\mu_t)\Sigma_{t+1} X^{-1}A\mu_t \\
  \equiv & T_1+T_2+T_3
\end{align*}
separately, I find
\begin{align*}
  T_1 &= \ti{y}{t+1}^T \Sigma_O^{-1} \ti{y}{t+1} - \ti{y}{t+1}^T
  \Sigma_Y^{-1} \ti{y}{t+1} \\
  T_2 &= 2 \ti{y}{t+1}^T \Sigma_Y^{-1} OA\mu_t \\
  T_3 &= (A\mu_t)^T X^{-1} (A\mu_t) - (OA\mu_t)^T
  \Sigma_y^{-1}(OA\mu_t)
\end{align*}
Equation~\eqref{eq:new_R} follows pretty easily.

\section{Filtering}
\label{sec:filtering}

In this appendix I have two subsections that I wrote before I
realized that filtering is inappropriate for tracking.  In
\ref{sec:filtering1} I give a general recursive algorithm for filtering
for any state space model.  In \ref{sec:filter2} I discuss the
difficulty of filtering for the model of Section~\ref{sec:model1}


\subsection{General Filtering}
\label{sec:filtering1}

With the definitions
\begin{align}
  \label{def:alpha}
  \alpha_t &\equiv P(\ti{s}{t}|\ts{y}{\tau}{1}{t}) \text{ The updated distribution} \\
  f_t &\equiv P(\ti{s}{t}|\ts{y}{\tau}{1}{t-1}) \text{ The forecast
    distribution} \\
  \gamma_t &\equiv P(\ti{y}{t}|\ts{y}{\tau}{1}{t-1}) \text{ The
    incremental likelihood}
\end{align}
and applying a model characterized by the distributions
\begin{align}
  \label{def:alpha0}
  &\alpha_0  &&\text{The state prior} \\
  &P(\ti{s}{t+t}|\ti{s}{t}) &&\text{The state transition probability} \\
  &P(\ti{y}{t}|\ti{s}{t}) &&\text{The conditional observation probability}
\end{align}
I can write recursive filtering as follows:
\begin{align}
  f_t &= \EV{\alpha_{t-1}} {P(\ti{s}{t}|\ti{s}{t-1})} \\
  \gamma_t &= \EV{\ti{f}{t}} {P(\ti{y}{t}|\ti{s}{t})} \\
  \alpha_t &= \frac{f_t P(\ti{y}{t}|\ti{s}{t})}{\gamma_t} \\
\end{align}

\subsection{Filtering for Model One}
\label{sec:filter2}

With luck (I have not been so lucky with this application) one might
find a parametric form for the state prior $\alpha(0)$ (see
Eqn.~\eqref{def:alpha0}) that, combined with $\ti{y}{1}$, yields an
expression for $\alpha(1)$ that has the same parametric form.  Such a
form is called a \emph{conjugate family}.  Two particularly simple
cases are discrete hidden Markov models and Kalman filters.

Here, I will analyze the use of a Gaussian for $\alpha(0)$.  From that
choice it follows that each subsequent $\ti{\alpha}{t}$ is much more
complex.  Thus any actual implementation that starts with such an
$\alpha(0)$ must use simplifying approximations.  I will conclude the
section by considering a few such approximations.

Let me suppose that the initial state distribution is composed of
independent Gaussians, ie,
\begin{align*}
  \ti{\alpha}{0} &= P_{\os{S}{0,j}{j=1}{N} }\\
  &= \prod_{j=1}^{N} P_{\ti{S}{0,j}} \\
  &= \prod_{j=1}^{N} \normal{\mu_j}{\Sigma_j}.
\end{align*}
To find the forecast $\ti{f}{1}$, I can apply the state dynamics
\eqref{eq:dynamics} to each object independently with the result
\begin{align}
  \tilde \mu_j &= A \mu_j \\
  \tilde \Sigma_j &= A \Sigma_j A\transpose + \Sigma_D \\
  \label{eq:defF}
  (\tilde \mu_j, \tilde \Sigma_j ) &\equiv F(\mu_j,\Sigma_j) \\
  \label{eq:f1}
  \ti{f}{1} &= \prod_{j=1}^{N} {\cal N}(F(\mu_j,\Sigma_j)),
\end{align}
where Eqn.~\eqref{eq:defF} defines the map $F$ from a distribution at
time $t$ to a distribution at time $t+1$.  Note that like
$\ti{\alpha}{0}$, $\ti{f}{1}$ is simply Gaussian.  On the other hand
\begin{equation}
  \label{eq:a1}
  a(1) \equiv f(1) P_{y|S} = \frac{1}{\left| \M \right|} \sum_{M \in \M}
  \prod_{i=1}^N P(y(t,M(i)|s(t,i)) \cdot \left. {\cal
      N}(F(\mu_j,\Sigma_j))\right|_{s_i}
\end{equation}
which provides an unnormalized version of the updated distribution
$\alpha(1)$ has at least two unfortunate properties:
\begin{enumerate}
\item The distribution of states is a sum of $\left| \M \right|$
  Gaussians.  If you want to track $N=100$ objects, $\alpha(1)$ will
  have $\left| \M \right| = N! \approx 10^{156}$ terms.
\item For each term in the sum, the distributions of the separate
  objects $s_j$ are independent, but that independence property does
  not hold for the sum.  So it is not true that
  \begin{equation*}
    P(s(1)|y(1)) = \prod_{j=1}^N  P\left( \left( s(1,j) \right)|y(1)
    \right).
  \end{equation*}
\end{enumerate}

Leveraging the notational clarity of \eqref{eq:a1}, I can also write
\begin{align*}
  \ti{\alpha}{T} \propto \sum_{\os{M}{t}{t=1}{T}:\ti{M}{t}\in \M}
  \prod_{i=1}^N& \left[
  P\left( \os{y}{\ti{M}{t,i}}{t=1}{T} | \os{s}{t,i}{t=1}{T}\right) \right. \\
  & \left. P\left( \os{s}{t,i}{t=1}{T}| \ti{s}{0,i} \right)
  P\left( \ti{s}{0,i} \right) \right] .
\end{align*}
Since
\begin{equation*}
  P\left( \os{y}{\ti{M}{t,i}}{t=1}{T} | \os{s}{t,i}{t=1}{T}\right) =
  \prod_{t=1}^T P\left( \ti{y}{t,\ti{M}{t,i}} | \ti{s}{t,i}\right)
\end{equation*}
and
\begin{equation*}
  P\left( \os{s}{t,i}{t=1}{T}| \ti{s}{0,i} \right) = \prod_{t=1}^T
  P\left( \ti{s}{t,i} | \ti{s}{t-1,i}\right),
\end{equation*}
\begin{equation}
  \label{eq:alphaT}
  \ti{\alpha}{T} \propto \sum_{\os{M}{t}{t=1}{T}}
  \prod_{i=1}^N  P\left( \ti{s}{0,i} \right) \prod_{t=1}^T
  P\left( \ti{y}{t,\ti{M}{t,i}} | \ti{s}{t,i}\right)
  P\left( \ti{s}{t,i} | \ti{s}{t-1,i}\right).
\end{equation}
Like \eqref{eq:a1} \eqref{eq:alphaT} is a mixture of Gaussians.  The
number of components in the mixture $\left| \ts{M}{t}{1}{T}\right| =
(N!)^T$ is absurdly large.

\vfill \hrule To checkout: \emph{ svn --username you --password yours
  co svn://fraserphysics.com/ps}
\begin{verbatim}
$Id$
\end{verbatim}

\end{document}

%%%---------------
%%% Local Variables:
%%% eval: (load-file "SeqKeys.el")
%%% eval: (TeX-PDF-mode)
%%% End:
