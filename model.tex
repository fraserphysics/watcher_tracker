\documentclass[12pt]{article}

\usepackage{amsmath,amsfonts}
\usepackage{graphicx}
\usepackage{showlabels}

\newcommand{\normal}[2]{{\cal N}(#1,#2)}
\newcommand{\NormalE}[3]{{\mathcal{N}}\left.\left(#1,#2\right)\right|_{#3}}
\newcommand{\xdot}{{\dot x}}
\renewcommand{\th}{^{\text{th}}}
\newcommand{\field}[1]{\mathbb{#1}}
\newcommand{\REAL}{\field{R}}
\newcommand{\RATIONAL}{\field{Q}}
\newcommand{\INTEGER}{\field{Z}}
\newcommand{\EV}[2]{\field{E}_{#1}\left[#2\right]}
\newcommand{\M}{{\cal M}}
\newcommand{\transpose}{^\top}
\newcommand{\os}[4]{{\left[ #1(#2) \right]}_{#3}^{#4}} % Object sequence
\newcommand{\ti}[2]{{#1}{(#2)}}                         % Index
\newcommand{\ts}[4]{\os{#1}{#2}{#2=#3}{#4}} % Time series
%\newcommand{\ts}[4]{{\left[ #1(#2) \right]}_{#2=#3}^{#4}} % Sequence
\newcommand{\argmin}{\operatorname*{argmin}}
\newcommand{\argmax}{\operatorname*{argmax}}
\newcommand{\cS}{{\cal S}}
\newcommand{\logdet}{\log\left(\left|\Sigma_D\right| \left| \Sigma_O
    \right| \right)}

\title{Model Based Motion Detection}
\author{Andy Fraser}

\begin{document}
\maketitle

\section{Introduction}
\label{sec:introduction}

Frame by frame detection/tagging could use the result of a
\emph{filtered} forecast\footnote{$P(S(t)|\ts{y}{\tau}{1}{t-1})$ is
  the entire a posteriori distribution.}, ie,
\begin{equation*}
  P(S(t)|\ts{y}{\tau}{1}{t-1}).
\end{equation*}
Note that the maximum a posteriori (MAP) or \emph{decoded} track ie,
\begin{align*}
  \hat s_1^T &\equiv \argmax_{\ts{s}{\tau}{1}{T}}
  P(\ts{s}{\tau}{1}{T}|\ts{y}{\tau}{1}{T}) \\
  &= \argmax_{\ts{s}{\tau}{1}{T}} P(\ts{s}{\tau}{1}{T},\ts{y}{\tau}{1}{T})
\end{align*}
is different than the sequence of filtered forecasts.

\subsection{Filtering}
\label{sec:filtering}

With the definitions
\begin{align}
  \label{def:alpha}
  \alpha_t &\equiv P(\ti{s}{t}|\ts{y}{\tau}{1}{t}) \text{ The updated distribution} \\
  f_t &\equiv P(\ti{s}{t}|\ts{y}{\tau}{1}{t-1}) \text{ The forecast
    distribution} \\
  \gamma_t &\equiv P(\ti{y}{t}|\ts{y}{\tau}{1}{t-1}) \text{ The
    incremental likelihood}
\end{align}
and applying a model characterized by the distributions
\begin{align}
  \label{def:alpha0}
  &\alpha_0  &&\text{The state prior} \\
  &P(\ti{s}{t+t}|\ti{s}{t}) &&\text{The state transition probability} \\
  &P(\ti{y}{t}|\ti{s}{t}) &&\text{The conditional observation probability}
\end{align}
I can write recursive filtering as follows:
\begin{align}
  f_t &= \EV{\alpha_{t-1}} {P(\ti{s}{t}|\ti{s}{t-1})} \\
  \gamma_t &= \EV{\ti{f}{t}} {P(\ti{y}{t}|\ti{s}{t})} \\
  \alpha_t &= \frac{f_t P(\ti{y}{t}|\ti{s}{t})}{\gamma_t} \\
\end{align}

\subsection{Decoding}
\label{sec:decoding}

I will use the following definitions to describe decoding:
\begin{align*}
  u(\ts{s}{\tau}{1}{t}) & \quad \text{Utility of state sequence }
  \ts{s}{\tau}{1}{t}\\
  & \quad \equiv \log \left( P(\ts{y}{\tau}{1}{t},\ts{s}{\tau}{1}{t} \right)
  \\
  \nu(s,t) & \quad \text{Utility of best sequence ending with }
  \ti{s}{t} = s \\ 
  &  \quad \equiv \max_{\ts{s}{\tau}{1}{t}:\ti{s}{t}=s} u(\ts{s}{\tau}{1}{t}) \\
  u'(s,s',t) & \quad \text{Utility of best sequence ending with }
  \ti{s}{t},\ti{s}{t+1} = s,s' \\
  &  \quad \equiv \max_{\ts{s}{\tau}{1}{t+1}:\ti{s}{t}=s \&\ti{s}{t+1}=s'}
  u(\ts{s}{\tau}{1}{t+1}) \\
  B(s,t) & \quad \text{Best predecessor state given } \ti{s}{t+1}=s   
\end{align*}
I can evaluate the functions $B(*,t)$ and $\nu(*,t)$ recursively as
follows:
\begin{align*}
  u'(s,s',t) &= \nu(s,t) + \log\left( P_{\ti{s}{t+1}|}(s'|s) \right) +
  \log\left( P_{\ti{y}{t+1}|\ti{s}{t+1}}(\ti{y}{t+1}|s') \right) \\
  B(s,t) &= \argmax_{s'} u'(s',s,t)) \\
  \nu(s,t+1) &= u'(B(s,t),s,t)
\end{align*}
Given the functions $B(*,t)$ and $\nu(*,t)$ $\forall
t\in[1,\ldots,T]$, the following procedure decodes the best sequence
of states $ \ts{\hat s}{\tau}{1}{T}$ from a sequence of observations $
\ts{y}{\tau}{1}{T}$
\begin{align*}
  {\ti{{\hat s}}{T}} &= \argmax_s \nu(s,T) \\
  & \text{for } t \text{ from } T-1 \text{ to } 1: \\
  & \quad \ti{\hat s}{t} = B( \ti{\hat s}{t+1},t)
\end{align*}

\section{Model Version One}
\label{sec:model1}

In this section I describe the basic model \emph{MVI}.  I'll develop
algorithms and write code for \emph{MVI} for the baseline prototype of
the watcher project.  Later, I will compare proposed enhancements
against the performance of \emph{MVI}.

The number of moving objects is a constant $N$ over time.  At each
time $t$, the separate objects $\ti{s}{t,j}$ that constitute the state
evolve independently of each other.  The following equations describe
$P(\ti{s}{t+1,j}|\ti{s}{t,j})$, ie, the dynamics of each object:
\begin{subequations}
  \label{eq:dynamics}
  \begin{align}
    \ti{s}{t+1,j} &= A  \ti{s}{t,j} + \ti{\epsilon}{t,j}, &
    \ti{\epsilon}{t,j} &\sim \normal{0}{\Sigma_{D}} \text{ iid} \\
    A &= \begin{bmatrix}
      1 & 0 & 1 & 0 \\
      0 & 1 & 0 & 1 \\
      0 & 0 & 1 & 0 \\
      0 & 0 & 0 & 1
    \end{bmatrix} &
    \Sigma_{D} &= \begin{bmatrix}
      \sigma^2_{xD} & 0 & 0 & 0 \\
      0 & \sigma^2_{xD} & 0 & 0 \\
      0 & 0 & \sigma^2_{\xdot D} & 0 \\
      0 & 0 & 0 & \sigma^2_{\xdot D}
    \end{bmatrix}
  \end{align}
\end{subequations}
Each object has the following components at time $t$:
\begin{align*}
  &&s_{0}(t,j) & \text{ horizontal position} \\
  &&s_{1}(t,j) & \text{ vertical position} \\
  &&s_{2}(t,j) & \text{ horizontal velocity} \\
  &&s_{3}(t,j) & \text{ vertical velocity}
\end{align*}
In addition to the moving objects, a complete description of a state
$\ti{s}{t}$ includes a map $\ti{M}{t}\in \M$, where $\M$ is the set of
permutations of $N$ items.  I assume that $\ti{M}{t}$ is distributed
uniformly and independently of everything else, ie,
\begin{equation*}
  P(\ti{M}{t}) = \frac{1}{\left| \M\right|} =  \frac{1}{N!}.
\end{equation*}

An observation vector consists of locations
$\ti{y}{t}=\os{y}{t,i}{i=1}{N}$.  The probability that state
$\ti{s}{t}$ would produce observation $\ti{y}{t}$ is\footnote{This
  observation model describes indistinguishable observations.  An
  easier alternative would be objects that had different colors, or
  even easier, objects that had observable unique tags.}
\begin{equation}
  \label{eq:ob}
  P(\ti{y}{t}|\ti{s}{t}) =
    \frac{1}{\left|\M \right|} \sum_{M \in \M}
    \prod_{i=1}^{N} P(\ti{y}{t,M(i)}|\ti{s}{t,i}).
\end{equation}
with normal conditional observation distributions
\begin{equation*}
  \ti{y}{t,i}|\ti{s}{t,j} \sim
  \begin{cases}
    \NormalE{O\ti{s}{t,j}}{\Sigma_o}{\ti{y}{t,i}} & i = M(j) \\
    \text{Uniform} & \text{Otherwise}
  \end{cases}
\end{equation*}
where each mean comes from the projection
\begin{equation*}
  O = \begin{bmatrix} 1 & 0 & 0 & 0\\
    0 & 1 & 0 & 0 \end{bmatrix}
\end{equation*}
and each covariance is
\begin{equation*}
  \Sigma_o = \begin{bmatrix} \sigma_{xo}^2 & 0 \\ 0 &
    \sigma_{xo}^2 \end{bmatrix}.
\end{equation*}
In summary, aside from the initial state distribution, the model has
the following 3 degrees of freedom:
\begin{center}
  \begin{tabular}{|cp{15em}c|}
    \hline
    Symbol & Description & Degrees of freedom \\
    \hline
    $\Sigma_D$ & Dynamical noise & 2 \\
    $\Sigma_o$ & Observation noise & 1 \\
    \hline
  \end{tabular} 
\end{center}

\subsection{Filtering}
\label{sec:filter1}

With luck (I have not been so lucky with this application) one might
find a parametric form for the state prior $\alpha(0)$ (see
Eqn.~\eqref{def:alpha0}) that, combined with $\ti{y}{1}$, yields an
expression for $\alpha(1)$ that has the same parametric form.  Such a
form is called a \emph{conjugate family}.  Two particularly simple
cases are discrete hidden Markov models and Kalman filters.

Here, I will analyze the use of a Gaussian for $\alpha(0)$.  From that
choice it follows that each subsequent $\ti{\alpha}{t}$ is much more
complex.  Thus any actual implementation that starts with such an
$\alpha(0)$ must use simplifying approximations.  I will conclude the
section by considering a few such approximations.

Let me suppose that the initial state distribution is composed of
independent Gaussians, ie,
\begin{align*}
  \ti{\alpha}{0} &= P_{\os{S}{0,j}{j=1}{N} }\\
  &= \prod_{j=1}^{N} P_{\ti{S}{0,j}} \\
  &= \prod_{j=1}^{N} \normal{\mu_j}{\Sigma_j}.
\end{align*}
To find the forecast $\ti{f}{1}$, I can apply the state dynamics
\eqref{eq:dynamics} to each object independently with the result
\begin{align}
  \tilde \mu_j &= A \mu_j \\
  \tilde \Sigma_j &= A \Sigma_j A\transpose + \Sigma_D \\
  \label{eq:defF}
  (\tilde \mu_j, \tilde \Sigma_j ) &\equiv F(\mu_j,\Sigma_j) \\
  \label{eq:f1}
  \ti{f}{1} &= \prod_{j=1}^{N} {\cal N}(F(\mu_j,\Sigma_j)),
\end{align}
where Eqn.~\eqref{eq:defF} defines the map $F$ from a distribution at
time $t$ to a distribution at time $t+1$.  Note that like
$\ti{\alpha}{0}$, $\ti{f}{1}$ is simply Gaussian.  On the other hand
\begin{equation}
  \label{eq:a1}
  a(1) \equiv f(1) P_{y|S} = \frac{1}{\left| \M \right|} \sum_{M \in \M}
  \prod_{i=1}^N P(y(t,M(i)|s(t,i)) \cdot \left. {\cal
      N}(F(\mu_j,\Sigma_j))\right|_{s_i}
\end{equation}
which provides an unnormalized version of the updated distribution
$\alpha(1)$ has at least two unfortunate properties:
\begin{enumerate}
\item The distribution of states is a sum of $\left| \M \right|$
  Gaussians.  If you want to track $N=100$ objects, $\alpha(1)$ will
  have $\left| \M \right| = N! \approx 10^{156}$ terms.
\item For each term in the sum, the distributions of the separate
  objects $s_j$ are independent, but that independence property does
  not hold for the sum.  So it is not true that
  \begin{equation*}
    P(s(1)|y(1)) = \prod_{j=1}^N  P\left( \left( s(1,j) \right)|y(1)
    \right).
  \end{equation*}
\end{enumerate}

Leveraging the notational clarity of \eqref{eq:a1}, I can also write
\begin{align*}
  \ti{\alpha}{T} \propto \sum_{\os{M}{t}{t=1}{T}:\ti{M}{t}\in \M}
  \prod_{i=1}^N& \left[
  P\left( \os{y}{\ti{M}{t,i}}{t=1}{T} | \os{s}{t,i}{t=1}{T}\right) \right. \\
  & \left. P\left( \os{s}{t,i}{t=1}{T}| \ti{s}{0,i} \right)
  P\left( \ti{s}{0,i} \right) \right] .
\end{align*}
Since
\begin{equation*}
  P\left( \os{y}{\ti{M}{t,i}}{t=1}{T} | \os{s}{t,i}{t=1}{T}\right) =
  \prod_{t=1}^T P\left( \ti{y}{t,\ti{M}{t,i}} | \ti{s}{t,i}\right)
\end{equation*}
and
\begin{equation*}
  P\left( \os{s}{t,i}{t=1}{T}| \ti{s}{0,i} \right) = \prod_{t=1}^T
  P\left( \ti{s}{t,i} | \ti{s}{t-1,i}\right),
\end{equation*}
\begin{equation}
  \label{eq:alphaT}
  \ti{\alpha}{T} \propto \sum_{\os{M}{t}{t=1}{T}}
  \prod_{i=1}^N  P\left( \ti{s}{0,i} \right) \prod_{t=1}^T
  P\left( \ti{y}{t,\ti{M}{t,i}} | \ti{s}{t,i}\right)
  P\left( \ti{s}{t,i} | \ti{s}{t-1,i}\right).
\end{equation}
Like \eqref{eq:a1} \eqref{eq:alphaT} is a mixture of Gaussians.  The
number of components in the mixture $\left| \ts{M}{t}{1}{T}\right| =
(N!)^T$ is absurdly large.

\subsubsection{Approximating with $\hat M$}
\label{sec:Mhat.filter1}

Approximate the sum with a single $\ts{\hat M}{t}{1}{T}$.  Try to select
$\ts{\hat M}{t}{1}{T}$ to get the biggest term in the sum.
Alternatively, use a few terms.

\subsection{Decoding}
\label{sec:decode1}

A solution to the decoding problem
\begin{align*}
  \hat s_1^T &\equiv \argmax_{s_1^T} P(s_1^T|y_1^{t-1}) \\
            &=  \argmax_{s_1^T} P(s_1^T,y_1^{t-1})
\end{align*}
contains only a single sequence of permutations $\ts{\hat
  M}{t}{1}{T}$.  Thus I need not approximate a mixture of Gaussians.

\subsubsection{Single Sequence}
\label{sec:single-sequence}

I'll begin by considering decoding a trajectory of a single object
from a single sequence of observations.  Using the notation in
Section~\ref{sec:decoding}, and assuming that $\nu(s,t)$ is quadratic,
I can write the following recursion:
\begin{align}
  \nu(s,t) &= -\frac{1}{2}(s-\mu_{t})^T
    \Sigma_{t}^{-1}(s-\mu_{t}) + R_t \nonumber \\
  \label{eq:decode_u'}
  u'(s,s',t) &= \nu(s,t) -\frac{1}{2} \logdet  - 
  \frac{1}{2}(s'-As)^T \Sigma_{D}^{-1} (s'-As)  \nonumber \\
  &\quad - \frac{1}{2}(\ti{y}{t+1} - O s')^T \Sigma_{O}^{-1}(\ti{y}{t+1}
    - O s') \\
  B(s,t) &= \argmax_{q} u'(q,s,t) \nonumber \\
  \label{eq:decode_B}
  &= \left( \Sigma_t^{-1} + A^T \Sigma_D^{-1} A \right)^{-1} \left(
    \Sigma_t^{-1} \mu_t + A^T \Sigma_D^{-1} s \right) \\
  \nu(s,t+1) &= u'(B(s,t),s,t) \nonumber \\
  &\equiv  -\frac{1}{2}(s-\mu_{t+1})^T
  \Sigma_{t+1}^{-1}(s-\mu_{t+1}) + R_{t+1} \nonumber \\
  \label{eq:new_Sigma}
  \Sigma_{t+1}^{-1} & = O^T\Sigma_O^{-1} O + \left( \Sigma_D + A \Sigma_t
    A^T \right)^{-1} \\
  \label{eq:new_mu}
  \mu_{t+1} &= A \mu_t + \Sigma_{t+1} O^T \Sigma_O^{-1} (\ti{y}{t+1} -
  OA \mu_t) \\
  R_{t+1} &= R_t -\frac{1}{2} ( \mu_t^T A^T (A\Sigma_t A^T +
  \Sigma_D)^{-1} A \mu_t  + y^T \Sigma_Oy \nonumber \\
  \label{eq:new_R}
  & \quad \quad \quad \quad - \mu^T_{t+1} \Sigma_{t+1}^{-1} \mu_{t+1} + \logdet )
\end{align}
I derive \eqref{eq:decode_B} by
solving\footnote{The derivation of \eqref{eq:decode_B}:
  \begin{align*}
    \frac{d u'(q,s,t)}{d q} &= -\Sigma_t^{-1}(q-\mu_t) + A^T \Sigma_D^{-1}
    (s - Aq) \\
    &= \Sigma_t^{-1}\mu_t + A^T \Sigma_D^{-1} s -(\Sigma_t^{-1} +
    A^T\Sigma_D^{-1}A)q \\
    q &= \left( \Sigma_t^{-1} + A^T\Sigma_D^{-1}A\right)^{-1} \left(
      \Sigma_t^{-1}\mu_t + A^T \Sigma_D^{-1} s \right)
  \end{align*}
}
\begin{equation*}
  \frac{d u'(q,s,t)}{d q} = 0.
\end{equation*}
Note that the independent variable $s$ in \eqref{eq:decode_B} is the
state at the future time $t+1$, while in \eqref{eq:decode_u'}, $s$ is
the state at the earlier time $t$.  See Appendix~\ref{app:decode} for
the derivation of \eqref{eq:new_Sigma} and \eqref{eq:new_mu}.  I am
surprised that the resulting recursion for $\nu(s,t)$ is exactly
Kalman filtering.

% \subsubsection{Joint Probabilistic Data Association}
% \label{sec:JPDA1}

% \subsubsection{Multiple Hypothesis Tracking}
% \label{sec:MHT1}

\appendix
\section{Derivation of Formulas for Decoding the Trajectory of a Single Object}
\label{app:decode}

I obtain \eqref{eq:new_Sigma} and \eqref{eq:new_mu} by expanding
$u'(B(s,t),s,t)$ and completing the square.  I'll abbreviate $B(s,t)$
with $B$, using the notation
\begin{align*}
  B &\equiv \left( \Sigma_t^{-1} + A^T \Sigma_D^{-1} A \right)^{-1}
  \left( \Sigma_t^{-1} \mu_t + A^T \Sigma_D^{-1} s \right) \\
  &= G + Fs \\
  G &\equiv \left( \Sigma_t^{-1} + A^T \Sigma_D^{-1} A \right)^{-1}
  \Sigma_t^{-1} \mu_t \\
  F &\equiv  \left( \Sigma_t^{-1} + A^T \Sigma_D^{-1} A \right)^{-1}
  A^T \Sigma_D^{-1}.
\end{align*}
I find
\begin{align*}
  \nu(s,t+1) &= -\frac{1}{2}(B-\mu_{t})^T \Sigma_{t}^{-1}
  (B-\mu_{t}) + R_t\\
  &\quad - \frac{1}{2} (s-AB)^T \Sigma_{D}^{-1} (s-AB)\\
  &\quad - \frac{1}{2}(\ti{y}{t+1}-O s)^T \Sigma_{O}^{-1}
  (\ti{y}{t+1}-Os) -\frac{1}{2} \logdet\\
  -2 \nu(s,t+1) &= (G-\mu_{t}+Fs)^T \Sigma_{t}^{-1} (G-\mu_{t}+Fs) \\
  &\quad + ((1-AF)s-AG)^T \Sigma_{D}^{-1} ((1-AF)s-AG)\\
  &\quad + (\ti{y}{t+1}-O s)^T \Sigma_{O}^{-1} (\ti{y}{t+1}-Os) -2R_t \\
  &\equiv s^T q s - 2s^T l + c.
\end{align*}
To express $\nu_{t+1}$ in terms of $\Sigma_{t+1}$, $\mu_{t+1}$, and
$R_{t+1}$, I will use the following formulas:
\begin{align*}
  \Sigma_{t+1}^{-1} &= q \\
  \mu_{t+1} &= \Sigma_{t+1} l \\
  R_{t+1} &= -\frac{1}{2} \left( c - \mu_{t+1}^T \Sigma_{t+1}^{-1}
    \mu_{t+1} \right) .
\end{align*}
The quadratic term is
\begin{align*}
  q &= F^T\Sigma_t^{-1}F + (1-AF)^T\Sigma_D^{1-}(1-AF) +
  O^T\Sigma_O^{-1}O \\
  &= O^T\Sigma_O^{-1}O + \Sigma_D^{-1} - \Sigma_D^{-1}A
  ( \Sigma_t^{-1} + A^T\Sigma_D^{-1}A )^{-1}A^T\Sigma_D^{-1}\\
  &= O^T\Sigma_O^{-1}O + (\Sigma_D + A \Sigma_t A^T)^{-1}
\end{align*}
where the last line follows from the matrix inversion lemma, ie,
\begin{equation*}
  (L^{-1} + H^T J^{-1} H)^{-1} = L - LH^T (HLH^T + J)^{-1} HL.
\end{equation*}
Equation~\eqref{eq:new_Sigma} follows from $\Sigma_{t+1}^{-1} = q$.
The linear term is
\begin{align*}
  l &= O^T\Sigma_O^{-1}y(t+1) - F^T \Sigma_t^{-1}(G-\mu_t) +
  (1-AF)^T\Sigma_D^{-1}AG \\
  &= O^T\Sigma_O^{-1}y(t+1) + \Sigma_D^{-1}A \left( \Sigma_t^{-1} +
    A^T \Sigma_D^{-1} A \right)^{-1} \Sigma_t^{-1} \mu_t.
\end{align*}

While I could (and have with much pain) derive Eqn.~\eqref{eq:new_mu}
from the formula $\mu_{t+1} = \Sigma_{t+1} l$, here I only verify that
$q \mu_{t+1} = l$.  I will use the following lemma:
\begin{align*}
  (q-O^T\Sigma^{-1}O)A &= \left( \Sigma_D^{-1} - \Sigma_D^{-1} A (
    \Sigma_t^{-1} + A^T \Sigma_D^{-1} A)^{-1} A^T \Sigma_D^{-1}
  \right) A \\
  &= (\Sigma_D + A \Sigma_t A^T)^{-1} A \quad \text{ by matrix inversion
    lemma} \\
  &= (A \Sigma_D + \Sigma_t A^T)^{-1} \\
  &= (\Sigma_t^{-1} A \Sigma_D + A^T)^{-1} \Sigma_t^{-1}\\
  &= \Sigma_D^{-1} (\Sigma_t^{-1} A  + A^T\Sigma_D^{-1})^{-1} \Sigma_t^{-1}\\
  &= \Sigma_D^{-1} A (\Sigma_t^{-1}  + A^T\Sigma_D^{-1} A)^{-1} \Sigma_t^{-1}.
\end{align*}
Now the verification is simply:
\begin{align*}
  q \mu_{t+1} &= qA\mu_t + O^T \Sigma_O^{-1} \ti{y}{t+1} - O^T
  \Sigma_O O A \mu_t \\
  &= O^T \Sigma_O^{-1} \ti{y}{t+1} + (q - O^T \Sigma_O O) A \mu_t \\
  &= O^T\Sigma_O^{-1}y(t+1) + \Sigma_D^{-1}A \left( \Sigma_t^{-1} +
    A^T \Sigma_D^{-1} A \right)^{-1} \Sigma_t^{-1} \mu_t \quad \text{
    by the lemma}\\
  &= l.
\end{align*}

Using the the following abbreviation and calculation
\begin{align*}
  H &\equiv (\Sigma_t^{-1} + A^T \Sigma_D^{-1}A)^{-1} \Sigma_t^{-1} \\
  &= 1 - \Sigma_t A^T(A\Sigma_t A^T + \Sigma_D)^{-1} A \quad \text{ By
    matrix inversion lemma}
\end{align*}
I write the constant term as
\begin{align*}
  c &= \mu_t^T \left( (H-1)^T\Sigma_t^{-1} (H-1) + H^TA^T\Sigma_D^{-1}
    AH \right) \mu_t + \ti{y^T}{t+1} \Sigma_O^{-1}
  \ti{y}{t+1} - 2R_t + \logdet\\
  &= \mu_t^T  A^T(A\Sigma_t A^T + \Sigma_D)^{-1}A \mu_t
  + \ti{y^T}{t+1} \Sigma_O^{-1} \ti{y}{t+1} - 2R_t  + \logdet,
\end{align*}
and find
\begin{equation*}
  R_{t+1} = R_t -\frac{1}{2} \mu_t^T  A^T(A\Sigma_t A^T +
  \Sigma_D)^{-1}A \mu_t -\frac{1}{2}\ti{y^T}{t+1} \Sigma_O^{-1}
  \ti{y}{t+1} + \frac{1}{2}  \mu_{t+1}^T \Sigma_{t+1}^{-1}
  \mu_{t+1} -\frac{1}{2} \logdet
\end{equation*}



\newpage
\hrule
From here on I've just kept old text that I might use again as I
develop the document.\\
\hrule
\section{Model}
\label{sec:model}

The number of moving objects in my model is a constant $N_s$ over
time.  Objects may or may not be visible.  At time $t$, visibility,
position, and velocity
\begin{equation*}
  \ti{s}{j,t} \equiv \left(\ti{v}{j,t},\ti{x}{j,t},\ti{\dot x}{j,t} \right)
\end{equation*}
characterize the state of the $j\th$ object, and the vector
\begin{equation*}
  \ti{s}{t} \equiv \os{s}{j,t}{j=1}{N_s}
\end{equation*}
constitutes the entire state.  Each visibility component has three
possible values with the following interpretation
\begin{equation*}
  \ti{v}{j,t} =
  \begin{cases}
    1 & \text{Object is visible} \\
    2 & \text{Object is not visible for this frame} \\
    3 & \text{Object is not visible for at least three frames}
  \end{cases}
\end{equation*}
The components $\ti{s}{j,t}$ of the state evolve independently of each
other.  The following equations describe
$P(\ti{s}{j,t+1}|\ti{s}{j,t})$, ie, the dynamics of each component:
\begin{subequations}
  \label{eq:dynamics}
  \begin{align}
    P_{\ti{v}{j,t+1}|\ti{v}{j,t}} &= V, & V &=
    \begin{bmatrix}
      P(1 \rightarrow 1) & P(1 \rightarrow 2) & 0 \\
      P(2 \rightarrow 1) & P(2 \rightarrow 2) & P(2 \rightarrow 3) \\
      0 & P(3 \rightarrow 2) & P(3 \rightarrow 3)
    \end{bmatrix} \\
    \begin{bmatrix} \ti{x}{j,t+1} \\ \ti{\xdot}{j,t+1} \end{bmatrix}
    &= A   \begin{bmatrix} \ti{x}{j,t} \\ \ti{\xdot}{j,t} \end{bmatrix}
    + \epsilon_{j,t}, & \epsilon_{j,t} &\sim
    \normal{0}{\Sigma_{D}} \text{ iid} \\
    A &= \begin{bmatrix}
      1 & 0 & 1 & 0 \\
      0 & 1 & 0 & 1 \\
      0 & 0 & 1 & 0 \\
      0 & 0 & 0 & 1
    \end{bmatrix} &
    \Sigma_{D} &= \begin{bmatrix}
      \sigma^2_{xD} & 0 & 0 & 0 \\
      0 & \sigma^2_{xD} & 0 & 0 \\
      0 & 0 & \sigma^2_{\xdot D} & 0 \\
      0 & 0 & 0 & \sigma^2_{\xdot D}
    \end{bmatrix}
  \end{align}
\end{subequations}

An observation vector consists of $N_y$ locations
$\ti{y}{t}=\os{y}{t,i}{i=1}{N_y}$, and the probability that state $\ti{s}{t}$
would produce observation $\ti{y}{t}$ is
\begin{equation}
  \label{eq:ob}
  P(\ti{y}{t}|\ti{s}{t}) \equiv
  \begin{cases}
    0 & \text{if} N_y \neq N_{\text{visible}} \\
    \frac{1}{\left|\M \right|} \sum_{M \in \M}
    \prod_{i=1}^{N_y} P(\ti{y}{t,M(i)}|\ti{s}{t,i}) & \text{otherwise}
  \end{cases}
\end{equation}
where $\M$ is the set of permutations of $N_y$ items\footnote{This
  observation model describes indistinguishable observations.  An
  easier alternative would be objects that had different colors, or
  even easier, objects that had observable unique tags.},
\begin{equation*}
  \ti{y}{t,i}|\ti{s}{t,j} \sim
  \NormalE{\ti{x}{t,j}}{\Sigma_o}{\ti{y}{t,i}} \text{ and }
  \Sigma_o = \begin{bmatrix} \sigma_{xo}^2 & 0 \\ 0 &
    \sigma_{xo}^2 \end{bmatrix}.
\end{equation*}
In summary, aside from the initial state distribution, the model has
the following 7 degrees of freedom:
\begin{center}
  \begin{tabular}{|cp{15em}c|}
    \hline
    Symbol & Description & Degrees of freedom \\
    \hline
    $T$ & Probabilities of transition between visibility levels & 4 \\
    $\Sigma_D$ & Dynamical noise & 2 \\
    $\Sigma_o$ & Observation noise & 1 \\
    \hline
  \end{tabular} 
\end{center}

\section{Forward algorithm}
\label{sec:forward}

A complete model consists of seven parameters described in
Section~\ref{sec:model} and an initial distribution over states, ie,
$P_{s(0)}$.  Given a sequence $\os{y}{t}{t=1}{T}$ of $T$ vectors of
measurements and a complete model, the forward algorithm calculates a
sequence of \emph{forecasts} $\os{f}{t}{t=1}{T}$ and \emph{updates}
$\os{\alpha}{t}{t=1}{T}$.  Each forecast $\ti{f}{t}$ characterizes the
conditional distribution of states given all measurements up to the
previous time
\begin{equation*}
  \ti{f}{t} \rightarrow P(\ti{s}{t+1}|\os{y}{\tau}{\tau=1}{t}).
\end{equation*}
and each update $\ti{\alpha}{t}$ characterizes the conditional
distribution of states given all measurements up to the present time
\begin{equation*}
  \ti{\alpha}{t} \rightarrow P(\ti{s}{t}|\os{y}{\tau}{\tau=1}{t}).
\end{equation*}
I will denote the initial distribution over states as
$\ti{\alpha}{0}$.

The forward algorithm is recursive.  Each full iteration of the
recursion uses $\ti{y}{t+1}$ and $\ti{\alpha}{t}$ to calculate
$\ti{\alpha}{t+1}$ in the following steps:
\begin{subequations}
  \label{eq:Forward}
\begin{align}
  \label{eq:f1}
  \ti{f}{t+1} &\equiv P_{\ti{s}{t+1}|\os{y}{\tau}{\tau=1}{t}} =
  \EV{\ti{\alpha}{t}}{P(\ti{s}{t+1}|\ti{s}{t})} \\ 
  \label{eq:f2}
  \ti{a}{t+1} &\equiv
  P_{\ti{y}{t+1},\ti{s}{t+1}|\os{y}{\tau}{\tau=1}{t}} = P_{y|s}
  \ti{f}{t+1} \\
  \label{eq:f3}
  \ti{\gamma}{t+1} &\equiv P(\ti{y}{t+1}|\os{y}{\tau}{\tau=1}{t}) = \EV{\ti{f}{t+1}}{P(\ti{y}{t+1}|\ti{s}{t+1})} \\
  \label{eq:f4}
  \ti{\alpha}{t+1} &= \frac{\ti{a}{t+1}}{\ti{\gamma}{t+1}}
\end{align}
\end{subequations}
where the items on the left have the following interpretations:
\begin{description}
\item[$\ti{f}{t+1}$] A distribution of states $s$
\item[$\ti{a}{t+1}$] An unnormalized distribution of states $s$
\item[$\ti{\gamma}{t+1}$] A scalar; the conditional probability of the
  observation $\ti{y}{t+1}$ given the model and the previous observations
\item[$\ti{\alpha}{t+1}$] A distribution of states $s$
\end{description}

Each forecast and update characterizes a distribution of possible
states and thus has the same structure with the following
constituents\footnote{This is wrong.  The first update operation
  produces a mixture of Gaussians with $N_s$ components, and each
  subsequent update increases the number of components by another
  factor of $N_s$.}:
\begin{subequations}
  \label{eq:psForm}
  \begin{align}
    P_j &\equiv \begin{bmatrix} P_{v_j}(1), P_{v_j}(2), P_{v_j}(3)
    \end{bmatrix}, ~\forall j\\
    \mu_j &\equiv \begin{bmatrix} \mu_{j,1} \\ \mu_{j,2} \\ \mu_{j,3} \\
      \mu_{j,4} \end{bmatrix}, ~\forall j\\
    \Sigma_j, &~~~~~\forall j
  \end{align}
\end{subequations}

Using Eqn.~\eqref{eq:dynamics}, I implement step~\eqref{eq:f1} by:
\begin{subequations}
  \label{eq:f1I}
  \begin{align}
    P_{vfj} &= P_{v\alpha j} T\\
    \mu_{fj} &= A \mu_{\alpha j}\\
    \Sigma_{fj} &= A \Sigma_{\alpha j} A\transpose + \Sigma_D
  \end{align}
\end{subequations}

It would be nice if step~\eqref{eq:f2} lead to each component say
$a_j$ being the distribution of a weighted sum of variables with
distributions $f_k$ because that will lead to $\ti{\alpha}{t+1}$ having the
form \eqref{eq:psForm}, but $a_j$ is simply a weighted sum of the
distributions $f_k$, ie, an ugly mixture of Gaussians.

Roughly:
\begin{align*}
  a(s) &= \sum_M \prod_j P(y_{M(j)}|s_j) f(s_j) \\
  a(s_j) &= \sum_i  P(y_i|s_j) f(s_j) \sum_{M:M(j)=i}  \prod_k
  P(y_{M(k)}|s_k) f(s_k)\\
  &= \sum_i  P(y_i|s_j) f(s_j) w_{i,j} \\
  &= \sum_i  w_{i,j} \NormalE{x_j}{\Sigma_{xo}}{y_i}
  \NormalE{\mu_{fj}}{\Sigma_{fj}}{\begin{bmatrix} x_j\\ \xdot_j
    \end{bmatrix}}
\end{align*}


\subsection{Fudge}
\label{sec:fudge}

The following adjustments come to mind:
\begin{description}
\item[Hard sphere:] Require $\left|\mu_{j,1:2} - \mu_{k,1:2} \right| >
  \delta,~\forall j,k$
\item[Bounded positions:] Require $0 < \mu_{j,1} <
  \text{max}_1,~\forall j$ with a similar requirement for component 2
\item[Bounded velocities:] Require $0 < \mu_{j,3} <
  \text{max}_3,~\forall j$ with a similar requirement for component 4
\item[Bounded variance] Complicated bounds on $\Sigma_{\alpha,j}$ and
  $\Sigma_{a,j}$
\end{description}

\vfill \hrule
In \emph{svn://fraserphysics.com/ps}.
\begin{verbatim}
$Id$
\end{verbatim}

\end{document}

%%%---------------
%%% Local Variables:
%%% eval: (load-file "SeqKeys.el")
%%% eval: (TeX-PDF-mode)
%%% End:
